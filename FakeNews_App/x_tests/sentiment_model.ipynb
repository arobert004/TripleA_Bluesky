{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aro40\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love this product! It's absolutely amazing.\n",
      "[{'label': 'love', 'score': 0.8030408620834351}, {'label': 'admiration', 'score': 0.7699857354164124}, {'label': 'joy', 'score': 0.027310136705636978}]\n",
      "This is the worst experience I've ever had.\n",
      "[{'label': 'disgust', 'score': 0.2684014141559601}, {'label': 'disappointment', 'score': 0.21605296432971954}, {'label': 'annoyance', 'score': 0.18567699193954468}]\n",
      "I'm feeling great today, everything is going well.\n",
      "[{'label': 'joy', 'score': 0.6397374272346497}, {'label': 'admiration', 'score': 0.5056352019309998}, {'label': 'approval', 'score': 0.10274945944547653}]\n",
      "I'm so disappointed with the service, it was terrible.\n",
      "[{'label': 'disappointment', 'score': 0.5121172070503235}, {'label': 'sadness', 'score': 0.17005327343940735}, {'label': 'fear', 'score': 0.10088013857603073}]\n",
      "What a fantastic movie! I enjoyed every moment of it.\n",
      "[{'label': 'admiration', 'score': 0.7756890654563904}, {'label': 'joy', 'score': 0.7384395003318787}, {'label': 'amusement', 'score': 0.05662013217806816}]\n",
      "I can't stand this anymore, it's so frustrating!\n",
      "[{'label': 'annoyance', 'score': 0.6180362105369568}, {'label': 'anger', 'score': 0.44268369674682617}, {'label': 'disapproval', 'score': 0.06244802474975586}]\n",
      "The food was delicious, I would definitely come back.\n",
      "[{'label': 'admiration', 'score': 0.9100810885429382}, {'label': 'approval', 'score': 0.1991250216960907}, {'label': 'optimism', 'score': 0.03705957904458046}]\n",
      "I'm feeling a bit down today, not my best day.\n",
      "[{'label': 'disappointment', 'score': 0.6016541123390198}, {'label': 'sadness', 'score': 0.18194401264190674}, {'label': 'annoyance', 'score': 0.09390919655561447}]\n",
      "The skye is blue\n",
      "[{'label': 'neutral', 'score': 0.9667752385139465}, {'label': 'approval', 'score': 0.02142111398279667}, {'label': 'realization', 'score': 0.00810204166918993}]\n",
      "I regret buying this, it was a complete waste of money.\n",
      "[{'label': 'remorse', 'score': 0.7472405433654785}, {'label': 'sadness', 'score': 0.21044132113456726}, {'label': 'disappointment', 'score': 0.07952441275119781}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
    "\n",
    "sentences = [\n",
    "    \"I love this product! It's absolutely amazing.\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "    \"I'm feeling great today, everything is going well.\",\n",
    "    \"I'm so disappointed with the service, it was terrible.\",\n",
    "    \"What a fantastic movie! I enjoyed every moment of it.\",\n",
    "    \"I can't stand this anymore, it's so frustrating!\",\n",
    "    \"The food was delicious, I would definitely come back.\",\n",
    "    \"I'm feeling a bit down today, not my best day.\",\n",
    "    \"The skye is blue\",\n",
    "    \"I regret buying this, it was a complete waste of money.\"\n",
    "]\n",
    "\n",
    "for sentence in sentences : \n",
    "    model_outputs = classifier(sentence)\n",
    "    print(sentence)\n",
    "    print(model_outputs[0][:3])\n",
    "# produces a list of dicts for each of the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'love', 'score': 0.8030411601066589},\n",
       " {'label': 'admiration', 'score': 0.7699856162071228},\n",
       " {'label': 'joy', 'score': 0.027310099452733994}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, XLMRobertaForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "\n",
    "inputs = tokenizer(\"Aliens does not exist. It's proved\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]\n",
    "\n",
    "# To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n",
    "num_labels = len(model.config.id2label)\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\", num_labels=num_labels)\n",
    "\n",
    "labels = torch.tensor([1])\n",
    "loss = model(**inputs, labels=labels).loss\n",
    "round(loss.item(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opinion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch disponible: True\n",
      "TensorFlow disponible: True\n"
     ]
    }
   ],
   "source": [
    "from transformers.utils import is_torch_available, is_tf_available\n",
    "\n",
    "print(\"PyTorch disponible:\", is_torch_available())\n",
    "print(\"TensorFlow disponible:\", is_tf_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8486d10a33445e8753a8cf4316d985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aro40\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aro40\\.cache\\huggingface\\hub\\models--lighteternal--fact-or-opinion-xlmr-el. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b12cb9ff464e5ebe78561ba09e272e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/398 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0ecf54c40a49109651fd7aa6636910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7057a97af2af44d99e635f7263a384c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8b4ea5c6724731bf7e424e95d2a34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a0a995e4fe49428762451fd82b4155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"lighteternal/fact-or-opinion-xlmr-el\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9958229064941406}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LABEL 1 : FACT / OBJECTIVE\n",
    "\n",
    "pipe('We can see through datas that Immigration is very dangerous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9966098666191101}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LABEL_0: Fake news\n",
    "\n",
    "from transformers import pipeline\n",
    "MODEL = \"jy46604790/Fake-News-Bert-Detect\"\n",
    "clf = pipeline(\"text-classification\", model=MODEL, tokenizer=MODEL)\n",
    "\n",
    "\n",
    "text = \"While the King volunteered to accept up to 2,000 Palestinian children from Gaza in need of medical care, he stressed that rebuilding Gaza and addressing its humanitarian crisis should take precedence over relocation efforts.\"\n",
    "\n",
    "result = clf(text)\n",
    "result\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
